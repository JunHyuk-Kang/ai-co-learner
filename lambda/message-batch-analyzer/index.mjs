// Gemini imports
import { GoogleGenerativeAI } from "@google/generative-ai";
import { DynamoDBClient } from "@aws-sdk/client-dynamodb";
import { DynamoDBDocumentClient, ScanCommand, BatchWriteCommand, UpdateCommand, PutCommand } from "@aws-sdk/lib-dynamodb";

// Google Gemini í´ë¼ì´ì–¸íŠ¸
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

const dynamoClient = DynamoDBDocumentClient.from(
  new DynamoDBClient({ region: "ap-northeast-2" })
);

const SESSIONS_TABLE = process.env.SESSIONS_TABLE || "ai-co-learner-chat-sessions";
const ANALYTICS_TABLE = process.env.ANALYTICS_TABLE || "ai-co-learner-learning-analytics";
const MODEL_ID = "gemini-2.5-flash";

const BATCH_SIZE = 30; // í•œ ë²ˆì— ë¶„ì„í•  ë©”ì‹œì§€ ìˆ˜
const LOOKBACK_MINUTES = 10; // ìµœê·¼ 10ë¶„ê°„ ë©”ì‹œì§€ ì¡°íšŒ (5ë¶„ ìŠ¤ì¼€ì¤„ + ì—¬ìœ ë¶„)
const USAGE_TRACKING_TABLE = process.env.USAGE_TRACKING_TABLE || "ai-co-learner-usage-tracking";

// Exponential Backoff ì¬ì‹œë„ ì„¤ì •
const RETRY_CONFIG = {
  maxRetries: 3,
  initialDelay: 1000,  // 1ì´ˆ
  maxDelay: 10000,     // 10ì´ˆ
  backoffMultiplier: 2
};

// Exponential Backoff ì¬ì‹œë„ í—¬í¼ í•¨ìˆ˜
async function retryWithBackoff(fn, retries = RETRY_CONFIG.maxRetries) {
  let lastError;

  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;

      // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
      const isRetryable =
        error.message?.includes('quota') ||
        error.message?.includes('limit') ||
        error.message?.includes('RESOURCE_EXHAUSTED') ||
        error.status === 429 ||
        error.status === 503;

      // ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ì´ê±°ë‚˜ ë§ˆì§€ë§‰ ì‹œë„ì¸ ê²½ìš°
      if (!isRetryable || attempt === retries) {
        throw error;
      }

      // Exponential backoff ê³„ì‚°
      const delay = Math.min(
        RETRY_CONFIG.initialDelay * Math.pow(RETRY_CONFIG.backoffMultiplier, attempt),
        RETRY_CONFIG.maxDelay
      );

      console.log(`Retry attempt ${attempt + 1}/${retries} after ${delay}ms delay. Error: ${error.message}`);

      // ëŒ€ê¸°
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }

  throw lastError;
}

export const handler = async (event) => {
  console.log("ğŸš€ Starting batch message analysis...");

  try {
    // 1. ìµœê·¼ 5ë¶„ê°„ ë©”ì‹œì§€ ì¡°íšŒ
    const recentMessages = await getRecentMessages();

    if (recentMessages.length === 0) {
      console.log("â„¹ï¸ No recent messages to analyze");
      return { statusCode: 200, message: "No messages to analyze" };
    }

    console.log(`ğŸ“Š Found ${recentMessages.length} messages to analyze`);

    // 2. ë°°ì¹˜ë¡œ ê·¸ë£¹í™” (ìµœëŒ€ 30ê°œì”©)
    const batches = chunkArray(recentMessages, BATCH_SIZE);

    console.log(`ğŸ“¦ Created ${batches.length} batches`);

    // 3. ê° ë°°ì¹˜ ë¶„ì„
    let totalAnalyzed = 0;
    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i];
      console.log(`ğŸ” Analyzing batch ${i + 1}/${batches.length} (${batch.length} messages)`);

      const analysisResults = await analyzeBatch(batch);
      await saveAnalysisResults(analysisResults);

      totalAnalyzed += analysisResults.length;
      console.log(`âœ… Batch ${i + 1} complete: ${analysisResults.length} analyzed`);
    }

    console.log(`ğŸ‰ Batch analysis complete! Total analyzed: ${totalAnalyzed}`);

    return {
      statusCode: 200,
      body: JSON.stringify({
        message: "Batch analysis complete",
        totalAnalyzed,
        batches: batches.length
      })
    };

  } catch (error) {
    console.error("âŒ Error in batch analysis:", error);
    throw error;
  }
};

// ìµœê·¼ Në¶„ê°„ ë©”ì‹œì§€ ì¡°íšŒ
async function getRecentMessages() {
  const now = Date.now();
  const lookbackTime = now - (LOOKBACK_MINUTES * 60 * 1000);

  console.log(`â° Querying messages from ${new Date(lookbackTime).toISOString()} to ${new Date(now).toISOString()}`);

  const result = await dynamoClient.send(new ScanCommand({
    TableName: SESSIONS_TABLE,
    FilterExpression: "#ts >= :lookbackTime AND attribute_not_exists(analyzed)",
    ExpressionAttributeNames: {
      "#ts": "timestamp"
    },
    ExpressionAttributeValues: {
      ":lookbackTime": lookbackTime
    }
  }));

  return result.Items || [];
}

// ë°°ì¹˜ ë¶„ì„
async function analyzeBatch(messages) {
  const batchPrompt = buildBatchAnalysisPrompt(messages);

  console.log(`ğŸ“¤ Sending batch to Gemini (${messages.length} messages)...`);

  let inputTokens = 0;
  let outputTokens = 0;

  const analysisResults = await retryWithBackoff(async () => {
    const model = genAI.getGenerativeModel({
      model: MODEL_ID,
      generationConfig: {
        maxOutputTokens: 4000,
        temperature: 0.3
      }
    });

    const result = await model.generateContent(batchPrompt);
    const response = await result.response;
    const analysisText = response.text();

    // í† í° ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
    if (response.usageMetadata) {
      inputTokens = response.usageMetadata.promptTokenCount || 0;
      outputTokens = response.usageMetadata.candidatesTokenCount || 0;
      console.log(`ğŸ“Š Token usage: ${inputTokens} input, ${outputTokens} output`);
    }

    console.log(`ğŸ“¥ Received analysis from Gemini`);

    // JSON ë°°ì—´ ì¶”ì¶œ
    const jsonMatch = analysisText.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      console.error("Failed to extract JSON array from response:", analysisText.substring(0, 200));
      throw new Error("Failed to parse batch analysis response");
    }

    return JSON.parse(jsonMatch[0]);
  });

  // ì‚¬ìš©ëŸ‰ ì¶”ì 
  if (inputTokens > 0 || outputTokens > 0) {
    await trackUsage(inputTokens, outputTokens, messages.length);
  }

  // ë©”ì‹œì§€ ì •ë³´ì™€ ë¶„ì„ ê²°ê³¼ ë§¤í•‘
  return analysisResults.map((result, index) => ({
    ...messages[index],
    analysis: result
  }));
}

// ë°°ì¹˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
function buildBatchAnalysisPrompt(messages) {
  const messagesList = messages.map((msg, index) =>
    `${index + 1}. [messageId: ${msg.messageId}] ì‚¬ìš©ì: "${msg.userMessage}" / AI: "${msg.aiMessage}"`
  ).join('\n');

  return `
ë‹¹ì‹ ì€ í•™ìŠµ í–‰ë™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ${messages.length}ê°œì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ê°ê°ì˜ í•™ìŠµ ì—­ëŸ‰ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

ëŒ€í™” ëª©ë¡:
${messagesList}

ê° ëŒ€í™”ì— ëŒ€í•´ ë‹¤ìŒ 6ê°€ì§€ ì—­ëŸ‰ì„ 0-100ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , JSON ë°°ì—´ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

1. **ì§ˆë¬¸ í’ˆì§ˆ (questionQuality)**: ì§ˆë¬¸ì´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ë©° í•™ìŠµ ì˜ë„ê°€ ë¶„ëª…í•œê°€?
2. **ì‚¬ê³  ê¹Šì´ (thinkingDepth)**: ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ ì¶”êµ¬í•˜ê³  ë…¼ë¦¬ì  ì‚¬ê³ ê°€ ë³´ì´ëŠ”ê°€?
3. **ì°½ì˜ì„± (creativity)**: ë…ì°½ì ì´ê³  í™•ì¥ì ì¸ ì‚¬ê³ ë¥¼ í•˜ëŠ”ê°€?
4. **ì†Œí†µ ëª…í™•ì„± (communicationClarity)**: ìì‹ ì˜ ìƒê°ì„ ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ëŠ”ê°€?
5. **ì‹¤í–‰ë ¥ (executionOriented)**: ë°°ìš´ ë‚´ìš©ì„ ì‹¤ì œë¡œ ì ìš©í•˜ë ¤ëŠ” ì˜ì§€ê°€ ë³´ì´ëŠ”ê°€?
6. **í˜‘ì—…ë ¥ (collaborationSignal)**: í”¼ë“œë°±ì„ ìˆ˜ìš©í•˜ê³  ëŒ€í™”ë¥¼ ë°œì „ì ìœ¼ë¡œ ì´ì–´ê°€ëŠ”ê°€?

ì¶”ê°€ ì •ë³´:
- **ë©”ì‹œì§€ íƒ€ì…**: "question", "answer", "followup", "casual"
- **í•™ìŠµ ì¹´í…Œê³ ë¦¬**: "coding", "math", "science", "language", "general"

ì‘ë‹µ í˜•ì‹ (JSON ë°°ì—´ë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):
[
  {
    "messageId": "bot-123-1234567890",
    "questionQuality": 85,
    "thinkingDepth": 70,
    "creativity": 90,
    "communicationClarity": 75,
    "executionOriented": 80,
    "collaborationSignal": 65,
    "messageType": "question",
    "category": "coding"
  },
  {
    "messageId": "bot-456-1234567891",
    "questionQuality": 60,
    "thinkingDepth": 50,
    "creativity": 55,
    "communicationClarity": 70,
    "executionOriented": 40,
    "collaborationSignal": 60,
    "messageType": "casual",
    "category": "general"
  }
]

ì¤‘ìš”: ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì˜ JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
`;
}

// ë¶„ì„ ê²°ê³¼ ì €ì¥
async function saveAnalysisResults(results) {
  const TTL_1_YEAR = 365 * 24 * 60 * 60;

  // BatchWriteItemì€ ìµœëŒ€ 25ê°œ ì œí•œ
  const chunks = chunkArray(results, 25);

  for (const chunk of chunks) {
    // learning-analytics í…Œì´ë¸”ì— ì €ì¥ (BatchWrite ì‚¬ìš©)
    const analyticsRequests = chunk.map(result => ({
      PutRequest: {
        Item: {
          userId: result.userId,
          timestamp: result.timestamp,
          sessionId: result.sessionId,
          messageId: result.messageId,
          messageType: result.analysis.messageType || "question",
          userMessage: result.userMessage,
          aiMessage: result.aiMessage,
          analysisResult: {
            questionQuality: result.analysis.questionQuality,
            thinkingDepth: result.analysis.thinkingDepth,
            creativity: result.analysis.creativity,
            communicationClarity: result.analysis.communicationClarity,
            executionOriented: result.analysis.executionOriented,
            collaborationSignal: result.analysis.collaborationSignal
          },
          category: result.analysis.category || "general",
          expiresAt: Math.floor(Date.now() / 1000) + TTL_1_YEAR
        }
      }
    }));

    await dynamoClient.send(new BatchWriteCommand({
      RequestItems: {
        [ANALYTICS_TABLE]: analyticsRequests
      }
    }));

    // chat-sessions í…Œì´ë¸”ì— analyzed í”Œë˜ê·¸ ì„¤ì • (UpdateCommand ì‚¬ìš©)
    // BatchWriteì˜ PutRequestëŠ” ì „ì²´ ì•„ì´í…œì„ êµì²´í•˜ë¯€ë¡œ, ê¸°ì¡´ ë°ì´í„°ê°€ ì†ì‹¤ë  ìˆ˜ ìˆìŒ
    // UpdateCommandë¥¼ ì‚¬ìš©í•˜ì—¬ analyzed í”Œë˜ê·¸ë§Œ ì¶”ê°€
    for (const result of chunk) {
      await dynamoClient.send(new UpdateCommand({
        TableName: SESSIONS_TABLE,
        Key: {
          sessionId: result.sessionId,
          timestamp: result.timestamp
        },
        UpdateExpression: "SET analyzed = :analyzed, analysisTimestamp = :analysisTimestamp",
        ExpressionAttributeValues: {
          ":analyzed": true,
          ":analysisTimestamp": Date.now()
        }
      }));
    }
  }

  console.log(`ğŸ’¾ Saved ${results.length} analysis results to DynamoDB`);
}

// ë°°ì—´ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
function chunkArray(array, size) {
  const chunks = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
}

// ì‚¬ìš©ëŸ‰ ì¶”ì  í•¨ìˆ˜
async function trackUsage(inputTokens, outputTokens, batchSize) {
  // Gemini 2.5 Flash ê°€ê²© (2026ë…„ 1ì›” ê¸°ì¤€)
  const PRICING = {
    inputPer1M: 0.30,  // $0.30 per 1M input tokens
    outputPer1M: 2.50  // $2.50 per 1M output tokens
  };

  const estimatedCost =
    (inputTokens / 1_000_000) * PRICING.inputPer1M +
    (outputTokens / 1_000_000) * PRICING.outputPer1M;

  const timestamp = Date.now();
  const date = new Date().toISOString().split('T')[0];

  try {
    await dynamoClient.send(new PutCommand({
      TableName: USAGE_TRACKING_TABLE,
      Item: {
        userId: "SYSTEM_BATCH_ANALYZER",  // ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ê¸°ë¡
        timestamp,
        messageId: `batch-analyzer-${timestamp}`,
        sessionId: `batch-${date}`,
        date,
        service: "gemini",
        modelId: MODEL_ID,
        operation: "batch-analysis",
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens,
        estimatedCost,
        batchSize,  // ë¶„ì„í•œ ë©”ì‹œì§€ ìˆ˜
        createdAt: new Date().toISOString()
      }
    }));
    console.log(`ğŸ“Š Usage tracked: ${inputTokens} input + ${outputTokens} output tokens, cost: $${estimatedCost.toFixed(4)}`);
  } catch (error) {
    console.error("âš ï¸ Failed to track usage:", error.message);
    // ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë¡œì§ì€ ê³„ì† ì§„í–‰
  }
}
